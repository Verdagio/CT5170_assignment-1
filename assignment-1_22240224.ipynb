{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9045b48e",
   "metadata": {},
   "source": [
    "# CT5170 - Principles of Machine Learning\n",
    "### Assignment 1\n",
    "##### Daniel Verdejo - 22240224\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825891f9",
   "metadata": {},
   "source": [
    "1: _Have a look at the given data, understand the problem based on the dependent variable and select a machine learning category that can solve the task/problem.  Briefly explain why do you think it is the correct ML category for this problem?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e85a7f8",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "The data provided is a subset of the Iris dataset which typically includes 3 species. We have both a training and test dataset for our neural network to consume. \n",
    "\n",
    "To solve the problem we will use a supervised learning classification task as we are provided 80 samples in total in a training dataset. \n",
    "\n",
    "Classification will enable us to organise our data in categorical sense based off predictions made about each sample the model is given. \n",
    "\n",
    "We first train the model with a dataset of known data, consisting of 2 classes with 40 samples per class (as seen below), each sample containing 4 attributes and the target label. The attributes are the sepal width and length (in cm), and the petal width and length (in cm). \n",
    "\n",
    "Once trained we will then need to feed it new data (data it has not yet seen) to measure its performance.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097ee049",
   "metadata": {},
   "source": [
    "Lets begin..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11e02667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data:  [['setosa' '40']\n",
      " ['virginica' '40']]\n",
      "\n",
      "test data:  [['setosa' '10']\n",
      " ['virginica' '10']]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import keras as kr\n",
    "\n",
    "training_samples = list(csv.reader(open('./plant-data/plant-train.csv')))[1:]\n",
    "testing_samples = list(csv.reader(open('./plant-data/plant-test.csv')))[1:]\n",
    "\n",
    "# the attributes will be our inputs - sepal width, sepal length, petal width, petal length \n",
    "training_attributes = np.array(training_samples)[:,:4].astype(float)\n",
    "testing_attributes = np.array(testing_samples)[:,:4].astype(float)\n",
    "\n",
    "# The classes will be our outputs\n",
    "training_classes = np.array(training_samples)[:,4]\n",
    "testing_classes = np.array(testing_samples)[:,4]\n",
    "\n",
    "uniq_training_classes, output_indices, training_counts = np.unique(training_classes, return_counts=True, return_inverse=True)\n",
    "print('training data: ', np.asarray((uniq_training_classes, training_counts)).T)\n",
    "\n",
    "uniq_test_classes, test_counts = np.unique(testing_classes, return_counts=True)\n",
    "print('\\ntest data: ', np.asarray((uniq_test_classes, test_counts)).T)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eabe9a9",
   "metadata": {},
   "source": [
    "2: _Explore and report the data and its distribution among training and testing data. Can we call it imbalanced dataset, explain your answer (yes/no) briefly?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b41bc4",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "No, we cannot say the provided dataset is imbalanced. As we can see above, both the training and testing datasets show a 50:50 ratio for each class. The dataset is perfectly balanced with no specific class showing a majority or minority in either the training or testing datasets.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da31b8",
   "metadata": {},
   "source": [
    "3: _Research and write down about open-source machine learning package that are freely available, and select one that you think will be good and easy for this task. Your report should include a short overview of the main features of the package you have chosen._ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b92b3fa",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Some of the most popular machine learing libraries for python are as follows:\n",
    "\n",
    "**TensorFlow** - Developed by Google, written in Python and C++, it offers a free and open-source library used for artificial intelligence and machine learning applications. The library offers both a high-level and low-level API to users to enable creating machine leanring models which can be run on many different host devices including, cloud, desktop, mobile or even on edge devices. It offers tools to validate and transform large datasets, and tools to discover and remove bias in data to improve outcomes on models. Tensoflow offers in depth API documentation and learning materials for users of all experience levels.\n",
    "\n",
    "**Keras** - Is a machine learning API written purely in Python, which runs on top of the TensorFlow platform. It offers an easy to use high-level API which abstracts some of the more complex functionality of TensorFlow. Keras offers a quick and easy way to get up and running for smaller projects.\n",
    "\n",
    "It was built with simplicity in mind to promote fast prototyping via user friendliness, modularity and extensibility. Supports convolutional and recurrent networks, and can utilise either the host CPU or GPU for computational work.\n",
    "\n",
    "\n",
    "**PyTorch** - Developed by the Linux Foundation and Meta AI (a branch of Meta, formerly Facebook) was released in September 2016. The library is written in Python, CUDA and C++, and offers a machine learning framework based on the Torch library. It can be used to develop machine learning applications and also offers capabilities for the creation of REST API endpoint to ease application integration. It only offers low level apis so it can be more difficult to use than Keras.\n",
    "\n",
    "\n",
    "The machine learning library that I will be using here is [Keras](https://keras.io/). Its ease of use makes carrying out tasks like the one we are tackling today quick and easy. \n",
    "\n",
    "Using the Keras library over something like the TensorFlow or PyTorch libraries will reduce the amount of effort on my part to build the neural network, and should also be fairly easy to read and understand for you, the reader. As this dataset is quite small and relatively trivial using one of the other options, while they may operate faster, would add an unnecessary level of complexity as we should not need to dig into the lower level apis, or spend a lot of time debugging our neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbd8609",
   "metadata": {},
   "source": [
    "4: _In order to use the dataset (Plant-dataset) supplied below, you might need to do some work to prepare it for input into the ML package, depending on the ML category requirements. Document any data preparation (e.g. normalisation) steps in your report._\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfd809e",
   "metadata": {},
   "source": [
    "Some preparation of the dataset is required, we first got our attributes above like so: `attributes = np.array(training_samples)[:,:4].astype(np.float)` these our inputs.\n",
    "\n",
    "Next we got our classes: `training_classes = np.array(training_samples)[:,4]` these will be our outputs.\n",
    "\n",
    "Above we used `uniq_training_classes, inverse, training_counts = np.unique(training_classes, return_counts=True, return_inverse=True)` for  the training dataset to view how the data is distributed among the 2 class in both datasets. We also got the indicies of the unique array. This consists of 0 and 1s which points us to the index for each output. As we can see below.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b5cad9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(output_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b834d49",
   "metadata": {},
   "source": [
    "5: _From the ML package, select two different algorithms from the category you selected and apply to the dataset. In your report, include a clear description of both algorithms. Ensure that you acknowledge all of your sources of information.\n",
    "Report the results with and without normalisation of the data._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bd9917",
   "metadata": {},
   "source": [
    "For our neural network we will use the Sigmoid and Softmax activation functions.\n",
    "\n",
    "**The Sigmoid Activation function**\n",
    "\n",
    "Formula:\n",
    "\n",
    "$ f(x) = 1 / 1+e^{-x} $\n",
    "\n",
    "The sigmoid function itself exists between 0 and 1 and takes an S shape curve. Since we are attempting to predict between 0 and 1 as we have just seen above from our `output_indices` list, the sigmoid activation function is the best fit here.\n",
    "\n",
    "This function is used in logistic regression to classify data. It takes a numeric input value and maps it to a probability between 0 and 1 like so: If the value is above 0.5 its 1, otherwise if its below 0.5 it 0 (rounding up or down to the nearest whole number). \n",
    "\n",
    "[Reference: O'Reilly - Introduction to Machine Learning with R: Scott V. Berger, Chapter 2: Supervised and Unsupervised Machine Learning - Neural Networks, Pages 35-36.](https://www.oreilly.com/library/view/introduction-to-machine/9781491976432/)\n",
    "\n",
    "[Reference: O'Reilly - Introduction to Machine Learning with R: Scott V. Berger, Chapter 4: Regression in a Nutshell - The Sigmoid Function, Page 94.](https://www.oreilly.com/library/view/introduction-to-machine/9781491976432/)\n",
    "\n",
    "We can plot out the Sigmoid activation funtion using matplotlib and the equation: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d29cfb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import plot, show\n",
    "from math import exp\n",
    "        \n",
    "xAxis = np.arange(-10., 10., 0.2)\n",
    "sigmoid = [ 1/(1+exp(-item)) for item in xAxis]\n",
    "\n",
    "plot(xAxis, sigmoid)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9520b2",
   "metadata": {},
   "source": [
    "\n",
    "**Softmax output layer**\n",
    "\n",
    "Formula:\n",
    "$ f(x)_i = e^{x_i} / \\sum^k _{j=1}   e^{x_j} $\n",
    "\n",
    "We want our output to be a probability distribution over a collection of classes. In this example we have 2 mutually exclusive classes `Setosa` and `Virginica`. Although it is not likely that the neural network will be able to predict the output with 100% accuracy, when we use a probability distribution we have a better idea of how accurate our predictions are. The output of a node in a softmax layer is dependant on all of the other nodes outputs in its layer as we require the sum of all outputs.\n",
    "\n",
    "[Reference: O'Reilly - Fundamentals of Deep Learning: Nikhil Buduma, Chapter 1: The Neural Network - Softmax Output Layer, Page 15.](https://www.oreilly.com/library/view/fundamentals-of-deep/9781492082170/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ebffeb",
   "metadata": {},
   "source": [
    "6: _Train and test your chosen algorithms using the training set provided in plant-train.csv. You should then test your trained models using the test set provided in plant-test.csv. Report on the results with appropriate performance metric e.g. accuracy that you consider best for each model on the training set and on the test set. Also include details of the classification models constructed â€“ these may include graphics if appropriate._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b369b0b6",
   "metadata": {},
   "source": [
    "We're going to create a neural network which will take 4 inputs (our 4 attributes: sepal width, sepal length, petal width, petal length). Then pass it through each layer, these layers contain nodes which are computational points. We add an activation function to each layer (sigmoid in this case) to be able to make these calculations. Finally they will be passed to the output layer in this case as a 0 (setosa) or 1 (virginica). \n",
    "\n",
    "Our neural network will resemble something like so:\n",
    "\n",
    "![neural net](assets/Neural_net.drawio.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83a15871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequential model\n",
    "model = kr.models.Sequential()\n",
    "\n",
    "#add our initial layer with an input for each of our attributes (4), and a hidden layer with 16 nodes\n",
    "model.add(kr.layers.Dense(16, input_shape=(4,)))\n",
    "\n",
    "# apply an activation function to the layer\n",
    "model.add(kr.layers.Activation('sigmoid'))\n",
    "\n",
    "# add our output layer with one node for each class\n",
    "model.add(kr.layers.Dense(2))\n",
    "\n",
    "# apply an activation function to the output layer sigmoid should be fine here\n",
    "model.add(kr.layers.Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040e3b41",
   "metadata": {},
   "source": [
    "\n",
    "We will use an optimizer with the aim to maximize the performance of our model by making iterative adjustments to its parameters to minimize error. This means we will avoid having to use a gradient descent strategy to minimize error.\n",
    "\n",
    "With gradient descent we would evaluate the gradient at a given starting position, find and travel in the direction of the steepest descent, from this new position we would repeat this process, continuing until we get to a point of minimum error. \n",
    "\n",
    "Thankfully, we do not have to worry about this when we use the Adam optimizer. Adam is an optimization algorithm that can be used instead of the classical stochastic gradient descent procedure in order to update network weights based on training data. \n",
    "The Adam algorithm calculates the exponentially weighted moving average of the gradient, and it estimates a vector in of the first moment of the gradient. In the second moments of the gradient another vector is estimated and the moving average of the historical gradients. The estimation of the vectors initial values to zero result in a bias relative to the real moments, thus a correction factor for both vector estimations is derived. This is Adam's corrective measure against the zero initialization bias.\n",
    "\n",
    "[Reference: O'Reilly - Fundamentals of Deep Learning: SNikhil Buduma, Chapter 2: Training Feed-Forward Neural Networks - Gradient Descent, Pages 19 - 20.](https://www.oreilly.com/library/view/fundamentals-of-deep/9781492082170/)\n",
    "\n",
    "[Reference: O'Reilly - Fundamentals of Deep Learning: SNikhil Buduma, Chapter 4: Beyond Gradient Descent - Adam-Combining momentum and RMSProp, Page 81.](https://www.oreilly.com/library/view/fundamentals-of-deep/9781492082170/)\n",
    "\n",
    "\n",
    "We will compile the the data using the Adam optimizer, and categorical cross entropy, for multi-class classification where each sample belongs to a single class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec733a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\danny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\danny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\danny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\danny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\danny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\danny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\danny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\danny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\danny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\danny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (1, 1) and (1, 2) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\danny\\dev\\machine-learning_CT5170\\CT5170_assignment-1\\assignment-1_22240224.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danny/dev/machine-learning_CT5170/CT5170_assignment-1/assignment-1_22240224.ipynb#X53sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39madam\u001b[39m\u001b[39m\"\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danny/dev/machine-learning_CT5170/CT5170_assignment-1/assignment-1_22240224.ipynb#X53sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#fit the model using our training data\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/danny/dev/machine-learning_CT5170/CT5170_assignment-1/assignment-1_22240224.ipynb#X53sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(training_attributes, training_classes, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danny/dev/machine-learning_CT5170/CT5170_assignment-1/assignment-1_22240224.ipynb#X53sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#evaluate the model using the test data set\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danny/dev/machine-learning_CT5170/CT5170_assignment-1/assignment-1_22240224.ipynb#X53sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m loss, accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(testing_attributes, testing_classes, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\danny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filejv9l9l5k.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\danny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\danny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\danny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\danny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\danny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\danny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\danny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\danny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\danny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\danny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (1, 1) and (1, 2) are incompatible\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# configure the model for training\n",
    "# uses the adam optimizer and categorial cross entropy as the loss function\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "#fit the model using our training data\n",
    "model.fit(training_attributes, training_classes, epochs=100, batch_size=1, verbose=1)\n",
    "#evaluate the model using the test data set\n",
    "loss, accuracy = model.evaluate(testing_attributes, testing_classes, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6541530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a967fd72",
   "metadata": {},
   "source": [
    "\n",
    "7: _Discuss in your report whether the two models give very similar or significantly different results, and why._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fb25cc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c69e896b73d80df03b10aefe902562c227bdab9e6e1527e46fe261fc763f811"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
